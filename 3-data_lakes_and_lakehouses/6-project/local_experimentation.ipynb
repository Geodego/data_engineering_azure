{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Local experimentation for Project 3\n",
    "This notebook is used to experiment with the code for Project 3. The code is then copied to the main notebook for the project."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95c43e5b68c850"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import datediff, floor, col, date_format, date_add, lit, unix_timestamp\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Project 3\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:37.761183Z",
     "start_time": "2024-02-24T14:57:32.818925Z"
    }
   },
   "id": "6b8913f412dbc28b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# read the csv files. These files don't have column names, so we need to specify them according to the schema provided in the project description.\n",
    "trip_columns= [\"trip_id\", \"rideable_type\", \"start_at\", \"ended_at\", \"start_station_id\", \"end_station_id\", \"rider_id\"]\n",
    "df_trips = spark.read.csv('data/trips.csv', header=False)\n",
    "df_trips = df_trips.toDF(*trip_columns)\n",
    "\n",
    "station_columns = [\"station_id\", \"name\", \"latitude\", \"longitude\"]\n",
    "df_stations = spark.read.csv('data/stations.csv', header=False)\n",
    "df_stations = df_stations.toDF(*station_columns)\n",
    "\n",
    "rider_columns = [\"rider_id\", \"first\", \"last\", \"address\", \"birthday\", \"account_start_date\", \"account_end_date\", \"is_member\"]\n",
    "df_rider = spark.read.csv('data/riders.csv', header=False)\n",
    "df_rider = df_rider.toDF(*rider_columns)\n",
    "\n",
    "payment_columns = [\"payment_id\", \"date\", \"amount\", \"rider_id\"]\n",
    "df_payments = spark.read.csv('data/payments.csv', header=False)\n",
    "df_payments = df_payments.toDF(*payment_columns)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:42.080251Z",
     "start_time": "2024-02-24T14:57:37.764932Z"
    }
   },
   "id": "831e45f38e191476",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+--------------------+----------+------------------+----------------+---------+\n",
      "|rider_id|   first|     last|             address|  birthday|account_start_date|account_end_date|is_member|\n",
      "+--------+--------+---------+--------------------+----------+------------------+----------------+---------+\n",
      "|    1000|   Diana|    Clark| 1200 Alyssa Squares|1989-02-13|        2019-04-23|            null|     True|\n",
      "|    1001|Jennifer|    Smith|     397 Diana Ferry|1976-08-10|        2019-11-01|      2020-09-01|     True|\n",
      "|    1002|   Karen|    Smith|644 Brittany Row ...|1998-08-10|        2022-02-04|            null|     True|\n",
      "|    1003|   Bryan|  Roberts|996 Dickerson Tur...|1999-03-29|        2019-08-26|            null|    False|\n",
      "|    1004|   Jesse|Middleton|7009 Nathan Expre...|1969-04-11|        2019-09-14|            null|     True|\n",
      "+--------+--------+---------+--------------------+----------+------------------+----------------+---------+\n"
     ]
    }
   ],
   "source": [
    "df_rider.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:42.324012Z",
     "start_time": "2024-02-24T14:57:42.083118Z"
    }
   },
   "id": "ba2c88d157ed6feb",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n",
      "|         trip_id|rideable_type|           start_at|           ended_at|start_station_id|end_station_id|rider_id|\n",
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n",
      "|89E7AA6C29227EFF| classic_bike|2021-02-12 16:14:56|2021-02-12 16:21:43|             525|           660|   71934|\n",
      "|0FEFDE2603568365| classic_bike|2021-02-14 17:52:38|2021-02-14 18:12:09|             525|         16806|   47854|\n",
      "|E6159D746B2DBB91|electric_bike|2021-02-09 19:10:18|2021-02-09 19:19:10|    KA1503000012|  TA1305000029|   70870|\n",
      "|B32D3199F1C2E75B| classic_bike|2021-02-02 17:49:41|2021-02-02 17:54:06|             637|  TA1305000034|   58974|\n",
      "|83E463F23575F4BF|electric_bike|2021-02-23 15:07:23|2021-02-23 15:22:37|           13216|  TA1309000055|   39608|\n",
      "+----------------+-------------+-------------------+-------------------+----------------+--------------+--------+\n"
     ]
    }
   ],
   "source": [
    "df_trips.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:42.509937Z",
     "start_time": "2024-02-24T14:57:42.323959Z"
    }
   },
   "id": "d7c79695a2d8787d",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+-----------------+------------------+\n",
      "|  station_id|                name|         latitude|         longitude|\n",
      "+------------+--------------------+-----------------+------------------+\n",
      "|         525|Glenwood Ave & To...|        42.012701|-87.66605799999999|\n",
      "|KA1503000012|  Clark St & Lake St|41.88579466666667|-87.63110066666668|\n",
      "|         637|Wood St & Chicago...|        41.895634|        -87.672069|\n",
      "|       13216|  State St & 33rd St|       41.8347335|       -87.6258275|\n",
      "|       18003|Fairbanks St & Su...|41.89580766666667|-87.62025316666669|\n",
      "+------------+--------------------+-----------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "df_stations.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:42.673480Z",
     "start_time": "2024-02-24T14:57:42.508079Z"
    }
   },
   "id": "5ecbceee125332dd",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------+--------+\n",
      "|payment_id|      date|amount|rider_id|\n",
      "+----------+----------+------+--------+\n",
      "|         1|2019-05-01|   9.0|    1000|\n",
      "|         2|2019-06-01|   9.0|    1000|\n",
      "|         3|2019-07-01|   9.0|    1000|\n",
      "|         4|2019-08-01|   9.0|    1000|\n",
      "|         5|2019-09-01|   9.0|    1000|\n",
      "+----------+----------+------+--------+\n"
     ]
    }
   ],
   "source": [
    "df_payments.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:42.800482Z",
     "start_time": "2024-02-24T14:57:42.668662Z"
    }
   },
   "id": "b68250282cf7878b",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------+---------+----------+---------+--------------------+\n",
      "|rider_id|             address|   first|     last|  birthday|is_member|age_at_account_start|\n",
      "+--------+--------------------+--------+---------+----------+---------+--------------------+\n",
      "|    1000| 1200 Alyssa Squares|   Diana|    Clark|1989-02-13|     True|                  30|\n",
      "|    1001|     397 Diana Ferry|Jennifer|    Smith|1976-08-10|     True|                  43|\n",
      "|    1002|644 Brittany Row ...|   Karen|    Smith|1998-08-10|     True|                  23|\n",
      "|    1003|996 Dickerson Tur...|   Bryan|  Roberts|1999-03-29|    False|                  20|\n",
      "|    1004|7009 Nathan Expre...|   Jesse|Middleton|1969-04-11|     True|                  50|\n",
      "+--------+--------------------+--------+---------+----------+---------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# Dim rider\n",
    "dim_rider = df_rider \\\n",
    "    .withColumn(\"age_at_account_start\", floor(datediff(\"account_start_date\", \"birthday\") / 365)) \\\n",
    "    .select(\"rider_id\", \"address\", \"first\", \"last\", \"birthday\", \"is_member\", \"age_at_account_start\")\n",
    "dim_rider.show(5)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T14:57:43.033575Z",
     "start_time": "2024-02-24T14:57:42.782692Z"
    }
   },
   "id": "df921d887778f944",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-----+-------+\n",
      "|date_key|week_day|month|quarter|\n",
      "+--------+--------+-----+-------+\n",
      "|20120101|     Sun|    1|      1|\n",
      "|20120102|     Mon|    1|      1|\n",
      "|20120103|     Tue|    1|      1|\n",
      "|20120104|     Wed|    1|      1|\n",
      "|20120105|     Thu|    1|      1|\n",
      "+--------+--------+-----+-------+\n"
     ]
    }
   ],
   "source": [
    "# dim date\n",
    "\n",
    "# Create a range of dates from 2012-01-01 to 2023-12-31\n",
    "date_range_df = spark.range(0, (365 * 12) + 3).selectExpr(\"CAST(id AS INT) AS id\") \n",
    "date_range_df = date_range_df \\\n",
    "    .withColumn(\"start_date\", lit(\"2012-01-01\")) \\\n",
    "    .withColumn(\"date\", date_add(\"start_date\", col(\"id\"))) \\\n",
    "    .select(\"date\")\n",
    "\n",
    "# Add additional columns\n",
    "dim_date = date_range_df \\\n",
    "    .withColumn(\"date_key\", date_format(\"date\", \"yyyyMMdd\").cast(\"int\")) \\\n",
    "    .withColumn(\"week_day\", date_format(\"date\", \"E\")) \\\n",
    "    .withColumn(\"month\", date_format(\"date\", \"M\").cast(\"int\")) \\\n",
    "    .withColumn(\"quarter\", date_format(\"date\", \"q\").cast(\"int\")) \\\n",
    "    .drop(\"date\")\n",
    "    \n",
    "\n",
    "dim_date.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:00:58.041760Z",
     "start_time": "2024-02-24T15:00:57.932668Z"
    }
   },
   "id": "bc7fc308a833a937",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+--------+--------------+\n",
      "|rider_id|payment_date|date_key|payment_amount|\n",
      "+--------+------------+--------+--------------+\n",
      "|    1000|  2019-05-01|20190501|           9.0|\n",
      "|    1000|  2019-06-01|20190601|           9.0|\n",
      "|    1000|  2019-07-01|20190701|           9.0|\n",
      "|    1000|  2019-08-01|20190801|           9.0|\n",
      "|    1000|  2019-09-01|20190901|           9.0|\n",
      "+--------+------------+--------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# fact payments\n",
    "fact_payments = df_payments \\\n",
    "    .withColumn(\"date_key\", date_format(\"date\", \"yyyyMMdd\").cast(\"int\")) \\\n",
    "    .withColumnRenamed('date', 'payment_date') \\\n",
    "    .withColumnRenamed('amount', 'payment_amount') \\\n",
    "    .select(\"rider_id\", \"payment_date\", \"date_key\", \"payment_amount\")\n",
    "\n",
    "fact_payments.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:01:00.307166Z",
     "start_time": "2024-02-24T15:01:00.193404Z"
    }
   },
   "id": "b83d6296c6e619f5",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+--------------+--------+-------------------+---------+-------------------+-------------------+--------+-------------+\n",
      "|         trip_id|start_station_id|end_station_id|rider_id|duration_in_minutes|rider_age|         started_at|           ended_at|date_key|starting_hour|\n",
      "+----------------+----------------+--------------+--------+-------------------+---------+-------------------+-------------------+--------+-------------+\n",
      "|89E7AA6C29227EFF|             525|           660|   71934|                  6|       37|2021-02-12 16:14:56|2021-02-12 16:21:43|20210212|           16|\n",
      "|0FEFDE2603568365|             525|         16806|   47854|                 19|       38|2021-02-14 17:52:38|2021-02-14 18:12:09|20210214|           17|\n",
      "|E6159D746B2DBB91|    KA1503000012|  TA1305000029|   70870|                  8|       33|2021-02-09 19:10:18|2021-02-09 19:19:10|20210209|           19|\n",
      "|B32D3199F1C2E75B|             637|  TA1305000034|   58974|                  4|       19|2021-02-02 17:49:41|2021-02-02 17:54:06|20210202|           17|\n",
      "|83E463F23575F4BF|           13216|  TA1309000055|   39608|                 15|       71|2021-02-23 15:07:23|2021-02-23 15:22:37|20210223|           15|\n",
      "+----------------+----------------+--------------+--------+-------------------+---------+-------------------+-------------------+--------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# fact trip\n",
    "# join df_trips with df_rider\n",
    "\n",
    "fact_trip = df_trips \\\n",
    "    .join(df_rider, \"rider_id\", \"inner\")\n",
    "fact_trip = fact_trip \\\n",
    "    .withColumn(\"date_key\", date_format(\"start_at\", \"yyyyMMdd\").cast(\"int\")) \\\n",
    "    .withColumn(\"start_timestamp\", unix_timestamp(\"start_at\")) \\\n",
    "    .withColumn(\"end_timestamp\", unix_timestamp(\"ended_at\")) \\\n",
    "    .withColumn('duration_in_minutes', ((col('end_timestamp') - col('start_timestamp')) / 60).cast(\"int\")) \\\n",
    "    .withColumn(\"starting_hour\", date_format(\"start_at\", \"H\").cast(\"int\")) \\\n",
    "    .withColumn('rider_age', floor(datediff(\"start_at\", \"birthday\") / 365)) \\\n",
    "    .withColumnRenamed('start_at', 'started_at') \\\n",
    "    .select(\"trip_id\",\"start_station_id\", \"end_station_id\", \"rider_id\",\n",
    "            \"duration_in_minutes\", \"rider_age\", \"started_at\", \"ended_at\", \"date_key\", \"starting_hour\")\n",
    "\n",
    "fact_trip.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:01:01.222630Z",
     "start_time": "2024-02-24T15:01:00.788451Z"
    }
   },
   "id": "3cae7304a75a5ddf",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-02-01 2022-02-01\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "min_date = df_payments.select(F.min(\"date\")).first()[0]\n",
    "max_date = df_payments.select(F.max(\"date\")).first()[0]\n",
    "print(min_date, max_date)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:01:02.434760Z",
     "start_time": "2024-02-24T15:01:01.403152Z"
    }
   },
   "id": "270d189236217fa3",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-01-01 2023-12-31\n"
     ]
    }
   ],
   "source": [
    "min_date = date_range_df.select(F.min(\"date\")).first()[0]\n",
    "max_date = date_range_df.select(F.max(\"date\")).first()[0]\n",
    "print(min_date, max_date)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-24T15:01:35.671649Z",
     "start_time": "2024-02-24T15:01:35.470512Z"
    }
   },
   "id": "c2f81ab31624af22",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f5a7e3e904cf34e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
